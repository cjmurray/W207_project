{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing Demand Kaggle project\n",
    "\n",
    "W207 Final Project\n",
    "\n",
    "Chris Murray, Rahul Ragunathan, Rajagopalan Mahadevan\n",
    "\n",
    "https://www.kaggle.com/c/bike-sharing-demand/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to read data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_data(data, is_test):\n",
    "    day_of_week=[]\n",
    "    months=[]\n",
    "    hours=[]\n",
    "    for i in range(data.shape[0]):\n",
    "       day_of_week.append(datetime.datetime.weekday(datetime.datetime.strptime(data[i][0], \"%Y-%m-%d %H:%M:%S\")))\n",
    "       #months.append(datetime.datetime.strptime(data[i][0], \"%Y-%m-%d %H:%M:%S\").month)\n",
    "       hours.append(datetime.datetime.strptime(data[i][0], \"%Y-%m-%d %H:%M:%S\").hour)\n",
    "    if not is_test:\n",
    "      data1 = np.empty([data.shape[0], 11], dtype=int)\n",
    "    else:\n",
    "      data1 = np.empty([data.shape[0], 8], dtype=int)\n",
    "    times = np.empty([data.shape[0]], dtype=\"S19\")\n",
    "    for i in range(data.shape[0]):\n",
    "       data1[i][0] = data[i][7]      # humidity\n",
    "       data1[i][1] = data[i][8]      # windspeed\n",
    "       data1[i][2] = hours[i]        # hour of the day\n",
    "       data1[i][3] = data[i][6]      # atemp\n",
    "       data1[i][4] = day_of_week[i]  # day of the week\n",
    "       data1[i][5] =  data[i][1]     # season    \n",
    "           \n",
    "       # Snow conditions\n",
    "       if data[i][4]==4:             # Weather\n",
    "         data1[i][6] = 3\n",
    "       else:\n",
    "         data1[i][6] = data[i][4]\n",
    "       data1[i][7] =  data[i][3]      # Is it a working day\n",
    "       \n",
    "       # For test data the casual rental count, reg rental count, and total count \n",
    "       if not is_test:\n",
    "         data1[i][8] = data[i][9]      # casual rentals\n",
    "         data1[i][9] = data[i][10]     # registered rentals\n",
    "         data1[i][10]= data[i][11]     # Total rental count\n",
    "                               \n",
    "       times[i] = data[i][0]         # datetime field\n",
    "    \n",
    "    return data1,times\n",
    "\n",
    "\n",
    "def readdata(filename, is_test):\n",
    "    # open the training file and extract column names\n",
    "    datafile = open(filename)\n",
    "    headers = datafile.readline()\n",
    "    print headers\n",
    "\n",
    "    # read data file and convert everything to integers\n",
    "    if is_test:\n",
    "        data1 = np.genfromtxt(datafile, delimiter=\",\", dtype=(\"|S19\", int, int, int, int, int, int, int, int))\n",
    "    else:\n",
    "        data1 = np.genfromtxt(datafile, delimiter=\",\", dtype=(\"|S19\", int, int, int, int, int, int, int, int, int, int, int))\n",
    "    \n",
    "    \n",
    "    \n",
    "    data, times = transform_data(data1, is_test)\n",
    "    \n",
    "    return times, headers, data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed,casual,registered,count\n",
      "\n",
      "Train data headers:\n",
      "datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed,casual,registered,count\n",
      "\n",
      "Sample training data:\n",
      "[[81  0  0 14  5  1  1  0]\n",
      " [80  0  1 13  5  1  1  0]\n",
      " [80  0  2 13  5  1  1  0]\n",
      " [75  0  3 14  5  1  1  0]\n",
      " [75  0  4 14  5  1  1  0]]\n",
      "\n",
      "Sample training labels (count):\n",
      "[3 8 5 3 0]\n",
      "[13 32 27 10  1]\n",
      "[16 40 32 13  1]\n",
      "['2011-01-01 00:00:00' '2011-01-01 01:00:00' '2011-01-01 02:00:00' ...,\n",
      " '2012-12-19 21:00:00' '2012-12-19 22:00:00' '2012-12-19 23:00:00']\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"data/train.csv\"\n",
    "test_filename = \"data/test.csv\"\n",
    "\n",
    "times, column_names_train, train = readdata(train_filename, False)\n",
    "\n",
    "# extract all but the last 3 columns into train_data\n",
    "train_data = train[:, :-3]\n",
    "\n",
    "# extract the last 3 columns (casual + registered = count)\n",
    "train_casual = train[:, 8]\n",
    "train_registered = train[:, 9]\n",
    "train_count = train[:, 10]\n",
    "\n",
    "print \"Train data headers:\"\n",
    "print column_names_train\n",
    "\n",
    "print \"Sample training data:\"\n",
    "print train_data[0:5]\n",
    "\n",
    "print \"\\nSample training labels (count):\"\n",
    "print train_casual[0:5]\n",
    "print train_registered[0:5]\n",
    "print train_count[0:5]\n",
    "print times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed\n",
      "\n",
      "\n",
      "Test data headers:\n",
      "datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed\n",
      "\n",
      "[[56 26  0 11  3  1  1  1]\n",
      " [56  0  1 13  3  1  1  1]\n",
      " [56  0  2 13  3  1  1  1]\n",
      " [56 11  3 12  3  1  1  1]\n",
      " [56 11  4 12  3  1  1  1]]\n"
     ]
    }
   ],
   "source": [
    "test_datetimes,column_names_test, test_data = readdata(test_filename,True )\n",
    "\n",
    "# print a sample of the test data\n",
    "print \"\\nTest data headers:\"\n",
    "print column_names_test\n",
    "print test_data[0:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CSV output function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writecsv(filename, predictions):\n",
    "    \n",
    "    # open output file and write header row\n",
    "    outfile = open(filename, \"w\")\n",
    "    outfile.write(\"datetime,count\\n\")\n",
    "\n",
    "    # output all the predictions to the file\n",
    "    for i in range(len(predictions)):\n",
    "        outfile.write(\"{},{}\\n\".format(test_datetimes[i], predictions[i]))\n",
    "\n",
    "    print \"{} results written to {}\".format(i, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions\n",
    "\n",
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6492 results written to submission_knn_1.csv\n",
      "6492 results written to submission_knn_3.csv\n",
      "6492 results written to submission_knn_5.csv\n",
      "6492 results written to submission_knn_7.csv\n",
      "6492 results written to submission_knn_9.csv\n"
     ]
    }
   ],
   "source": [
    "for k in [1,3,5,7,9]:\n",
    "    output_filename = 'submission_knn_{}.csv'.format(k)\n",
    "\n",
    "    # train a model and generate predictions\n",
    "    kn = KNeighborsClassifier(n_neighbors=k)\n",
    "    kn.fit(train_data, train_count)\n",
    "    preds = kn.predict(test_data)\n",
    "    \n",
    "    writecsv(output_filename, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6492 results written to submission_dtree_1.csv\n"
     ]
    }
   ],
   "source": [
    "output_filename = 'submission_dtree_1.csv'\n",
    "    \n",
    "# train a model and generate predictions\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(train_data, train_count)\n",
    "preds = clf.predict(test_data)\n",
    "\n",
    "writecsv(output_filename, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict **casual** and **registered** separately and then add together to get **count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6492 results written to submission_dtree_2.csv\n"
     ]
    }
   ],
   "source": [
    "output_filename = 'submission_dtree_2.csv'\n",
    "\n",
    "# train a model and generate predictions\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(train_data, train_casual)\n",
    "preds_casual = clf.predict(test_data)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(train_data, train_registered)\n",
    "preds_registered = clf.predict(test_data)\n",
    "\n",
    "preds = preds_casual + preds_registered\n",
    "\n",
    "writecsv(output_filename, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  3.  9.  3.]\n",
      "[  31.   35.   41. ...,  157.  172.  166.]\n",
      "[  31.   35.   41. ...,  160.  181.  169.]\n",
      "6492 results written to submission_lm_2.csv\n"
     ]
    }
   ],
   "source": [
    "output_filename = 'submission_lm_2.csv'\n",
    "# train GLM model\n",
    "lm = LinearRegression()\n",
    "lm.fit(train_data, train_casual)\n",
    "\n",
    "# make casual prediction\n",
    "preds_lm_casual = np.round(lm.predict(test_data))\n",
    "preds_lm_casual[preds_lm_casual < 0] = 0\n",
    "print preds_lm_casual\n",
    "\n",
    "#cmake registered prediction\n",
    "lm2 = LinearRegression()\n",
    "lm2.fit(train_data, train_registered)\n",
    "preds_lm_reg = np.round(lm2.predict(test_data))\n",
    "preds_lm_reg[preds_lm_reg < 0] = 0\n",
    "print preds_lm_reg\n",
    "preds = preds_lm_casual + preds_lm_reg\n",
    "print preds\n",
    "writecsv(output_filename, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21978756  0.19465538  0.19444223  0.15889514  0.10758317  0.06409945\n",
      "  0.04836203  0.01217505]\n",
      "[ 0.2413638   0.19827992  0.12020111  0.1949944   0.11421827  0.05924704\n",
      "  0.05614994  0.01554552]\n",
      "[ 13   4   4 ...,  89 102  41]\n",
      "6492 results written to RF.csv\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the classifier\n",
    "\n",
    "clf =   RandomForestClassifier(n_estimators=100, max_features=8)\n",
    "\n",
    "# Fit the training data\n",
    "clf.fit(train_data, train_casual)\n",
    "print clf.feature_importances_\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "preds1= clf.predict(test_data)\n",
    "\n",
    "clf2 = RandomForestClassifier(n_estimators=100, max_features=8)\n",
    "clf2.fit(train_data, train_registered)\n",
    "print clf2.feature_importances_\n",
    "\n",
    "preds2= clf2.predict(test_data)\n",
    "\n",
    "preds = preds1 + preds2\n",
    "\n",
    "            \n",
    "print preds\n",
    "# Write the predictions to a csv file\n",
    "writecsv('RF.csv', preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
